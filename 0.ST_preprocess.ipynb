{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058e554a-4e4f-42d7-b0fb-87d5ea1187c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T04:34:27.366669Z",
     "iopub.status.busy": "2025-07-06T04:34:27.365973Z",
     "iopub.status.idle": "2025-07-06T04:34:37.675261Z",
     "shell.execute_reply": "2025-07-06T04:34:37.673451Z",
     "shell.execute_reply.started": "2025-07-06T04:34:27.366605Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import itertools\n",
    "from skimage import io\n",
    "from scipy.sparse import csr_matrix # type: ignore\n",
    "from anndata import AnnData\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "sc.settings.verbosity = 3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import shapiro, norm\n",
    "from scipy.signal import find_peaks\n",
    "import os\n",
    "\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize']=(7,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706624b-65b7-4463-b66d-754baec44c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d289a7d-a058-412e-9936-42ccd7f53280",
   "metadata": {},
   "source": [
    "## Load stereos-seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2132f7-2b2d-41e7-80ca-021672a7728f",
   "metadata": {},
   "source": [
    "This module is used to read BGI data and image file, and return an AnnData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4648d05c-58f9-4f7c-81f7-e8ea1857765a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T04:34:44.709246Z",
     "iopub.status.busy": "2025-07-06T04:34:44.708105Z",
     "iopub.status.idle": "2025-07-06T04:34:44.749400Z",
     "shell.execute_reply": "2025-07-06T04:34:44.747363Z",
     "shell.execute_reply.started": "2025-07-06T04:34:44.709176Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_bin(\n",
    "    gem_file: str,\n",
    "    image_file: str,\n",
    "    bin_size: int,\n",
    "    library_id: str,\n",
    ") -> AnnData:\n",
    "    \"\"\"\n",
    "    Read BGI data and image file, and return an AnnData object.\n",
    "    Parameters\n",
    "    ----------\n",
    "    gem_file\n",
    "        The path of the BGI data file.\n",
    "    image_file\n",
    "        The path of the image file.\n",
    "    bin_size\n",
    "        The size of the bin.\n",
    "    library_id\n",
    "        The library id.\n",
    "    Returns\n",
    "    -------\n",
    "    Annotated data object with the following keys:\n",
    "\n",
    "        - :attr:`anndata.AnnData.obsm` ``['spatial']`` - spatial spot coordinates.\n",
    "        - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['images']`` - *hires* images.\n",
    "        - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['scalefactors']`` - scale factors for the spots.\n",
    "    \"\"\" # noqa: E501\n",
    "    library = library_id\n",
    "    dat_file = gem_file\n",
    "    image = image_file\n",
    "    bin_s = bin_size\n",
    "    ###########################\n",
    "    # different gem have different delimiter!!!!!!!\n",
    "    # COAD: \" \" , other may be \"\\t\"\n",
    "    dat = pd.read_csv(dat_file, delimiter=\"\\t\", comment=\"#\")\n",
    "    \n",
    "    image = cv2.imread(image)\n",
    "    ######\n",
    "    dat['x'] -= dat['x'].min()\n",
    "    dat['y'] -= dat['y'].min()\n",
    "\n",
    "    width = dat['x'].max() + 1\n",
    "    height = dat['y'].max() + 1\n",
    "    ###\n",
    "    dat['xp'] = (dat['x'] // bin_s) * bin_s\n",
    "    dat['yp'] = (dat['y'] // bin_s) * bin_s\n",
    "    dat['xb'] = np.floor(dat['xp'] / bin_s + 1).astype(int)\n",
    "    dat['yb'] = np.floor(dat['yp'] / bin_s + 1).astype(int)\n",
    "\n",
    "    dat['bin_ID'] = max(dat['xb']) * (dat['yb'] - 1) + dat['xb']\n",
    "    ###\n",
    "    trans_x_xb = dat[['x', 'xb']].drop_duplicates()\n",
    "    trans_x_xb = trans_x_xb.groupby('xb')['x'].apply(\n",
    "        lambda x: int(np.floor(np.mean(x)))).reset_index()\n",
    "    trans_y_yb = dat[['y', 'yb']].drop_duplicates()\n",
    "    trans_y_yb = trans_y_yb.groupby('yb')['y'].apply(\n",
    "        lambda y: int(np.floor(np.mean(y)))).reset_index()\n",
    "\n",
    "    trans_matrix = pd.DataFrame(list(itertools.product(\n",
    "        trans_x_xb['xb'], trans_y_yb['yb'])), columns=['xb', 'yb'])\n",
    "    trans_matrix = pd.merge(trans_matrix, trans_x_xb, on='xb')\n",
    "    trans_matrix = pd.merge(trans_matrix, trans_y_yb, on='yb')\n",
    "    trans_matrix['bin_ID'] = max(\n",
    "        trans_matrix['xb']) * (trans_matrix['yb'] - 1) + trans_matrix['xb']\n",
    "\n",
    "    trans_matrix['in_tissue'] = 1\n",
    "\n",
    "    tissue_positions = pd.DataFrame()\n",
    "    # barcode is str, not number\n",
    "    tissue_positions['barcodes'] = trans_matrix['bin_ID'].astype(str)\n",
    "    tissue_positions['in_tissue'] = trans_matrix['in_tissue']\n",
    "    tissue_positions['array_row'] = trans_matrix['yb']\n",
    "    tissue_positions['array_col'] = trans_matrix['xb']\n",
    "    tissue_positions['pxl_row_in_fullres'] = trans_matrix['y']\n",
    "    tissue_positions['pxl_col_in_fullres'] = trans_matrix['x']\n",
    "    tissue_positions.set_index('barcodes', inplace=True)\n",
    "\n",
    "    ### \n",
    "    if 'MIDCount' in dat.columns:\n",
    "        dat = dat.groupby(['geneID', 'xb', 'yb'])[\n",
    "            'MIDCount'].sum().reset_index()\n",
    "        dat['bin_ID'] = max(dat['xb']) * (dat['yb'] - 1) + dat['xb']\n",
    "\n",
    "        ### \n",
    "        unique_genes = dat['geneID'].unique()\n",
    "        unique_barcodes = dat['bin_ID'].unique()\n",
    "        gene_hash = {gene: index for index, gene in enumerate(unique_genes)}\n",
    "        barcodes_hash = {barcodes: index for index,\n",
    "                         barcodes in enumerate(unique_barcodes)}\n",
    "        dat['gene'] = dat['geneID'].map(gene_hash)\n",
    "        dat['barcodes'] = dat['bin_ID'].map(barcodes_hash)\n",
    "\n",
    "        ### \n",
    "        counts = csr_matrix((dat['MIDCount'], (dat['barcodes'], dat['gene'])))\n",
    "\n",
    "    else:\n",
    "        dat = dat.groupby(['geneID', 'xb', 'yb'])[\n",
    "            'MIDCounts'].sum().reset_index()\n",
    "        dat['bin_ID'] = max(dat['xb']) * (dat['yb'] - 1) + dat['xb']\n",
    "        ###\n",
    "        unique_genes = dat['geneID'].unique()\n",
    "        unique_barcodes = dat['bin_ID'].unique()\n",
    "        gene_hash = {gene: index for index, gene in enumerate(unique_genes)}\n",
    "        barcodes_hash = {barcodes: index for index,\n",
    "                         barcodes in enumerate(unique_barcodes)}\n",
    "        dat['gene'] = dat['geneID'].map(gene_hash)\n",
    "        dat['barcodes'] = dat['bin_ID'].map(barcodes_hash)\n",
    "\n",
    "        ###\n",
    "        counts = csr_matrix((dat['MIDCounts'], (dat['barcodes'], dat['gene'])))\n",
    "    adata = AnnData(counts)\n",
    "    adata.var_names = list(gene_hash.keys())\n",
    "    adata.obs_names = list(map(str, barcodes_hash.keys()))\n",
    "    ##########\n",
    "    adata.obs = adata.obs.join(tissue_positions, how=\"left\")\n",
    "    adata.obsm['spatial'] = adata.obs[[\n",
    "        'pxl_row_in_fullres', 'pxl_col_in_fullres']].to_numpy()\n",
    "    adata.obs.drop(columns=['in_tissue', 'array_row', 'array_col',\n",
    "                   'pxl_row_in_fullres', 'pxl_col_in_fullres'], inplace=True,)\n",
    "    ###\n",
    "    spatial_key = \"spatial\"\n",
    "    adata.uns[spatial_key] = {library: {}}\n",
    "    adata.uns[spatial_key][library][\"images\"] = {}\n",
    "    adata.uns[spatial_key][library][\"images\"] = {\"hires\": image}\n",
    "    # tissue image / RNA shape\n",
    "    tissue_hires_scalef = max(image.shape[0]/width, image.shape[1]/height)\n",
    "\n",
    "    # the diameter of detection area(the spot that contains tissue)\n",
    "    # can be adjust out side by size= in scatter function\n",
    "    spot_diameter = bin_s / tissue_hires_scalef\n",
    "    \n",
    "    #fiducial_area = max(tissue_positions['array_row'].max() - tissue_positions['array_row'].min(),\n",
    "    #                    tissue_positions['array_col'].max() - tissue_positions['array_col'].min())\n",
    "    adata.uns[spatial_key][library][\"scalefactors\"] = {\n",
    "        \"tissue_hires_scalef\": tissue_hires_scalef,\n",
    "        \"spot_diameter_fullres\": spot_diameter,\n",
    "    }\n",
    "\n",
    "    return adata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e9962-f6b4-454e-80e9-1ac372b2c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_cell(\n",
    "    gem_file: str,\n",
    "    image_file: str,\n",
    "    mask_file: int,\n",
    "    library_id: str,\n",
    ") -> AnnData:\n",
    "    \"\"\"\n",
    "    Read BGI data and image file, and return an AnnData object.\n",
    "    Parameters\n",
    "    ----------\n",
    "    gem_file\n",
    "        The path of the BGI data file.\n",
    "    image_file\n",
    "        The path of the image file.\n",
    "    bin_size\n",
    "        The size of the bin.\n",
    "    library_id\n",
    "        The library id.\n",
    "    Returns\n",
    "    -------\n",
    "    Annotated data object with the following keys:\n",
    "\n",
    "        - :attr:`anndata.AnnData.obsm` ``['spatial']`` - spatial spot coordinates.\n",
    "        - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['images']`` - *hires* images.\n",
    "        - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['scalefactors']`` - scale factors for the spots.\n",
    "    \"\"\" # noqa: E501\n",
    "    \n",
    "    # mask = pd.read_csv(mask_file, delimiter=\",\")\n",
    "    dat = pd.read_csv(gem_file, delimiter=\"\\t\", comment=\"#\")\n",
    "    image = io.imread(image_file)\n",
    "    \n",
    "    spatial_key = 'spatial'\n",
    "    library = library_id\n",
    "\n",
    "    mask = np.load(mask_file)\n",
    "    mask_nozero = np.nonzero(mask)\n",
    "    x = mask_nozero[0]; y = mask_nozero[1]\n",
    "    value = [mask[x[i],y[i]] for i in range(len(x))]\n",
    "    mask = pd.DataFrame({'x':y,'y':x,'barcodes':value})\n",
    "    \n",
    "    # stereoseq GEM xy is not the same as image xy\n",
    "    # exchange gem xy!\n",
    "    # !!!!!!!!!!!!!!!! \n",
    "    ##############y shall we? yes!\n",
    "    # dat = dat.rename(columns={'x': 'temp'})\n",
    "    # dat = dat.rename(columns={'y': 'x'})\n",
    "    # dat = dat.rename(columns={'temp': 'y'})  \n",
    "    # ######### \n",
    "    dat['x'] -= dat['x'].min()\n",
    "    dat['y'] -= dat['y'].min()\n",
    "    mask['x'] = mask['x'] - mask['x'].min()\n",
    "    mask['y'] = mask['y'] - mask['y'].min() \n",
    "    # 20230717\n",
    "    # dat['y'] = dat['y'].max() - dat['y'] # 为什么错了呢？\n",
    "    # dat['y'] = dat['y'][::-1]\n",
    "    \n",
    "    mask_data = pd.merge(left = mask, right = dat, on=['x', 'y'],how = \"inner\")\n",
    "\n",
    "    # mask_data for RNA\n",
    "    # mask for celluar location\n",
    "    exp = mask_data.groupby(['geneID', 'barcodes'])['MIDCount'].sum().reset_index()\n",
    "    \n",
    "    # construct count matrix\n",
    "    unique_genes = exp['geneID'].unique()\n",
    "    unique_barcodes = exp['barcodes'].unique()\n",
    "    gene_hash = {gene: index for index, gene in enumerate(unique_genes)}\n",
    "    barcodes_hash = {barcodes: index for index, barcodes in enumerate(unique_barcodes)}\n",
    "\n",
    "    exp['gene'] = exp['geneID'].map(gene_hash)\n",
    "    exp['barcodes'] = exp['barcodes'].map(barcodes_hash)\n",
    " \n",
    "    counts = csr_matrix((exp['MIDCount'], (exp['barcodes'], exp['gene']))) \n",
    "\n",
    "    adata = AnnData(counts)\n",
    "    adata.var_names = list(gene_hash.keys())\n",
    "    adata.obs_names = list(map(str, barcodes_hash.keys()))\n",
    "\n",
    "    # normalize mask coordinate to get mask and data overlap region\n",
    "    # this is to ensure cell position start from left upper corner\n",
    "    # according to mask, for we only care about \n",
    "\n",
    "    grouped_mask = mask.groupby('barcodes')\n",
    "    transform_mtx = pd.DataFrame(columns=['barcodes', 'center_x', 'center_y'])\n",
    "\n",
    "    for barcode, group in grouped_mask:\n",
    "        x_mean = int(np.floor(group['x'].mean()))\n",
    "        y_mean = int(np.floor(group['y'].mean()))\n",
    "        \n",
    "        # yanping 2023-07-03\n",
    "        # 'center_x': x_mean, 'center_y': y_mean\n",
    "        #transform_mtx = transform_mtx.append({'barcodes': str(barcode), 'center_x': x_mean, 'center_y': y_mean}, ignore_index=True)\n",
    "        transform_mtx = transform_mtx._append({'barcodes': str(barcode), 'center_x': x_mean, 'center_y': y_mean}, ignore_index=True)\n",
    "    \n",
    "    # reset index\n",
    "    transform_mtx.set_index('barcodes', inplace=True)\n",
    "\n",
    "    adata.obs = adata.obs.join(transform_mtx, how=\"left\")\n",
    "    adata.obsm['spatial'] = adata.obs[[ \"center_y\",\"center_x\"]].to_numpy()\n",
    "    \n",
    "    adata.obs.drop(columns=[\"center_x\", \"center_y\"], inplace=True)\n",
    "    \n",
    "    adata.uns[spatial_key] = {library: {}}\n",
    "    adata.uns[spatial_key][library][\"images\"] = {\"hires\": image}\n",
    "    ######\n",
    "    \n",
    "    tissue_hires_scalef = max((mask['y'].max()+1)/image.shape[1], (mask['x'].max()+1)/image.shape[0])\n",
    "    \n",
    "    # spot_diameter could be set to *mean pixel of mask* / hires_scalef\n",
    "    # can be adjust out side by size= in scatter function\n",
    "    adata.uns[spatial_key][library][\"scalefactors\"] = {\n",
    "         \"tissue_hires_scalef\": tissue_hires_scalef,\n",
    "         \"spot_diameter_fullres\": 250,\n",
    "    }\n",
    "    \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b001473-07c8-48b2-94dc-5280026b6419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09595b-33e1-4d49-a174-8b89ce5cf695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01ec7607-3ad6-46b5-b3f3-8f5ac41cbc29",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad09796-e9bc-45c5-9a7a-cc11cb3b0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_composition(adata, groupby_key, category_key):\n",
    "    \"\"\"\n",
    "    Calculate the composition of categories within each group.\n",
    "\n",
    "    Parameters:\n",
    "    adata: AnnData object\n",
    "    groupby_key: Key in adata.obs to group by (e.g., 'louvain')\n",
    "    category_key: Key in adata.obs for categories (e.g., 'annotations')\n",
    "\n",
    "    Returns:\n",
    "    Pandas DataFrame with composition data.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame from the AnnData object\n",
    "    data = pd.DataFrame(adata.obs)\n",
    "    # Calculate composition\n",
    "    composition = data.groupby(groupby_key)[category_key].value_counts(normalize=True).unstack(fill_value=0)\n",
    "    return composition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ed863-5535-46fd-87c0-228fc5cd2f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_composition(composition_df, title, x, y, palette='viridis'):\n",
    "    \"\"\"\n",
    "    Plot the composition data as a stacked bar plot.\n",
    "    Parameters:\n",
    "    composition_df: DataFrame with composition data\n",
    "    title: Title for the plot\n",
    "    \"\"\"\n",
    "    if isinstance(palette, str):\n",
    "        cmap = plt.get_cmap(palette)\n",
    "        colors = cmap(np.linspace(0, 1, composition_df.shape[1]))\n",
    "    elif isinstance(palette, list):\n",
    "        colors = palette\n",
    "    else:\n",
    "        raise ValueError(\"Palette should be a string (colormap name) or a list of colors\")\n",
    "    \n",
    "    # Create the plot\n",
    "    ax = composition_df.plot(kind='bar', stacked=True, figsize=(6, 4), color=colors, fontsize=8)\n",
    "    \n",
    "    # Set title and labels\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xlabel(x)\n",
    "\n",
    "    # Customize the legend\n",
    "    plt.legend(title=y, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Remove the top and right spines\n",
    "    sns.despine()\n",
    "\n",
    "    # Optional: Remove grid lines\n",
    "    ax.yaxis.grid(False)  # Remove horizontal grid lines\n",
    "    ax.xaxis.grid(False)  # Remove vertical grid lines\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0106e-35c9-4cf1-978c-6ac609818025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import dilation, square\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def compute_relative_abundance(adata, dict_use):\n",
    "    relative_abundances = {}\n",
    "    for cell_type, markers in tqdm(dict_use.items()):\n",
    "        avg_expressions = []\n",
    "        for marker in markers:\n",
    "            if marker not in adata.var_names:\n",
    "                continue\n",
    "            expressed_values = adata[:, marker].X[adata[:, marker].X > 0]\n",
    "            # Check if there are any expressed values\n",
    "            if isinstance(expressed_values, np.ndarray):\n",
    "                num_nonzero = len(expressed_values)\n",
    "            else:  # Assuming it's a sparse matrix\n",
    "                num_nonzero = expressed_values.getnnz()\n",
    "            if num_nonzero > 0:\n",
    "                avg_expressions.append(np.mean(expressed_values))\n",
    "            else:\n",
    "                avg_expressions.append(0)\n",
    "        relative_abundance = np.log10(sum(avg_expressions) + 1e-10)\n",
    "        relative_abundances[cell_type] = 1 / relative_abundance\n",
    "    return relative_abundances\n",
    "\n",
    "\n",
    "def annotate_cells_stage(marker_dict_use, adata, cells_to_annotate=None):\n",
    "    WCT = compute_relative_abundance(adata, marker_dict_use)\n",
    "    annotations = {}\n",
    "    unannotated_cells = []\n",
    "\n",
    "    if cells_to_annotate is None:\n",
    "        cells_to_annotate = adata.obs_names\n",
    "        data_submatrix = adata.X\n",
    "    else:\n",
    "        data_submatrix = adata[cells_to_annotate, :].X\n",
    "\n",
    "    all_scores = np.zeros((len(cells_to_annotate), len(marker_dict_use)))\n",
    "    print(all_scores.shape)\n",
    "    for idx, (cell_type, markers) in enumerate(marker_dict_use.items()):\n",
    "        valid_markers_indices = [\n",
    "            adata.var_names.get_loc(marker)\n",
    "            for marker in markers\n",
    "            if marker in adata.var_names\n",
    "        ]\n",
    "        marker_matrix = data_submatrix[:, valid_markers_indices]\n",
    "        presence_matrix = (marker_matrix > 0).astype(int)\n",
    "        scores = presence_matrix.sum(axis=1) * WCT[cell_type]\n",
    "\n",
    "        all_scores[:, idx] = scores.ravel()\n",
    "    max_scores = np.max(all_scores, axis=1)\n",
    "    max_score_indices = np.argmax(all_scores, axis=1)\n",
    "    cell_types = list(marker_dict_use.keys())\n",
    "    annotations = np.array(\n",
    "        [\n",
    "            cell_types[idx] if score > 0 else \"Others\"\n",
    "            for idx, score in zip(max_score_indices, max_scores)\n",
    "        ]\n",
    "    )\n",
    "    unannotated = [cells_to_annotate[i] for i in np.where(annotations == \"Others\")[0]]\n",
    "    return dict(zip(cells_to_annotate, annotations)), unannotated\n",
    "\n",
    "def visualize_results(adata, key=\"annotations\"):\n",
    "    # Plotting\n",
    "    cell_types, counts = np.unique(adata.obs[key], return_counts=True)\n",
    "    plt.bar(cell_types, counts)\n",
    "    # Annotate each bar with its value\n",
    "    for i, value in enumerate(counts):\n",
    "        plt.text(i, value, str(value), ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"Number of Cells\")\n",
    "    plt.xlabel(\"Cell Types\")\n",
    "    plt.title(\"Cell Type Annotations\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d2e022-06f1-43a1-8326-23289e8e00a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "203adaaa-8348-4bc0-b907-3c20e11c05f7",
   "metadata": {},
   "source": [
    "## Import cell merkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f49ebf-971e-4bca-9a1b-02f59aafed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./Files/markers.pkl', 'rb') as file: \n",
    "    marker_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac44fd-8e27-4d58-b0d7-c23b12a447ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126bbe2d-ad04-480b-b574-c2ded08a737b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2617f7d3-fe6f-49ba-84ed-a3c3e935fb8d",
   "metadata": {},
   "source": [
    "## Import data & cell type annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd525f-292f-497e-aeae-276722c20041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# please input the sample names\n",
    "samples = ['', '', '' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7075631-aea7-4392-be73-a4b4155aa6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sample in samples:\n",
    "    print(sample)\n",
    "\n",
    "    # input path\n",
    "    gem_file = './CRLM/' + sample + \"/results/\"\n",
    "    file_name = [x for x in os.listdir(gem_file) if \"tissue.gem.gz\" in x][0]\n",
    "    gem_file = './CRLM/' + sample + \"/results/\" + file_name\n",
    "    image_file = \"./gem_data/\" + sample + \"_tissue.tif\"\n",
    "    library_id = \"st\"\n",
    "\n",
    "    adata = ld.load_bin(gem_file, image_file, 20, library_id)\n",
    "\n",
    "    adata_copy = adata.copy()\n",
    "    sc.pp.filter_cells(adata, min_genes=1)\n",
    "    adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "    sc.pp.calculate_qc_metrics(\n",
    "        adata, qc_vars=[\"mt\"], percent_top=None, log1p=False, inplace=True\n",
    "    ) \n",
    "    adata.layers['counts'] = adata.X\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    print(adata)\n",
    "\n",
    "    annotations, unannotated_cells = annotate_cells_stage(marker_dict, adata)\n",
    "    print(\"There are {} cells remaining unannotated.\".format(len(unannotated_cells)))\n",
    "    adata.obs[\"annotations\"] = pd.Series(annotations).astype(\"category\")\n",
    "\n",
    "    # Identify the two types of cells\n",
    "    adata_epi = adata[adata.obs[\"annotations\"] == \"Epithelial\", :].copy()\n",
    "    annotations, unannotated_cells_stage_1 = annotate_cells_stage(marker_dict, adata_epi)\n",
    "    annotations_stage_2, unannotated = annotate_cells_stage( {key:val for key, val in marker_stage1.items() if key in [\"Malignant\", \"Epithelial\"]}, adata_epi,\n",
    "                                                            cells_to_annotate=unannotated_cells_stage_1) \n",
    "    for idx, ann in annotations_stage_2.items():\n",
    "        annotations[idx] = ann\n",
    "    adata_epi.obs[\"anno_1\"] = pd.Series(annotations).astype(\"category\")\n",
    "    adata_epi.obs['anno_1'] = np.array(adata_epi.obs['anno_1'])\n",
    "    adata.obs[\"annotations\"] = np.array(adata.obs[\"annotations\"])\n",
    "    adata.obs.loc[adata_epi.obs.index, \"annotations\"] = adata_epi.obs['anno_1']\n",
    "\n",
    "    \n",
    "    visualize_results(adata)\n",
    "    plt.rcParams['figure.figsize']=(4,4)\n",
    "    try:\n",
    "        sc.tl.rank_genes_groups(adata, groupby='annotations') \n",
    "        sc.pl.rank_genes_groups(adata)\n",
    "    except:\n",
    "        print('skip')\n",
    "\n",
    "    sc.pl.spatial(adata, color=[\"annotations\",'B2M'],size=0.3,img_key=None)\n",
    "    sc.pl.spatial(adata)\n",
    "\n",
    "    adata.obsm['spatial'] = np.array(adata.obsm['spatial']).astype(int)\n",
    "\n",
    "    ##### please complete the output path #####\n",
    "    adata.write_h5ad('./'+ sample + \".h5ad\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f8b0e3-b718-46e2-9212-84182fe6d68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b605c8-1cf4-4b01-931e-a1d5c2d9c982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a4e78-c324-43a5-9d82-8ac056c6ec66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ddccec-1fa4-40a2-9b64-12dbaa496bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36255362-0455-457e-90b5-7833a237c00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a2f8b-eeaf-477c-ba42-41e216e466dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4f377-b343-45f5-8cc1-e92fd1ffa0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d7849-d314-4018-96e9-9c1fd46219c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d9f583-1be7-42d4-9ea6-443b98dcaf66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0079c74-2039-4eb3-97ab-bb536a99d12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
